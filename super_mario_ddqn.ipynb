{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os, copy\n",
    "\n",
    "# GYM\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for GYM\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment\n",
    "import gym_super_mario_bros\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_state.shape: (240, 256, 3), reward: 0.0, done: False, info: {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# Initialize Super Mario environment with gym_super_mario_bros\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0', render_mode='rgb', apply_api_compatibility=True)\n",
    "\n",
    "# Limit the action-space to\n",
    "#   0. walk right\n",
    "#   1. jump right\n",
    "env = JoypadSpace(env, [['right'], ['right', 'A']])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(action=0)\n",
    "print(f\"next_state.shape: {next_state.shape}, reward: {reward}, done: {done}, info: {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess environment\n",
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "        \n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "    \n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose([T.Resize(self.shape), T.Normalize(0, 255)])\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "#env = AutoencoderObservation(env)\n",
    "env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "\n",
    "class MarioNet(nn.Module):\n",
    "    \"\"\"\n",
    "    mini cnn structure\n",
    "    input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.online = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "\n",
    "        self.target = copy.deepcopy(self.online)\n",
    "\n",
    "        # Q_target parameters are frozen\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "\n",
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Mario's DNN to predict the most optimal action - we implement this in the Learn section\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
    "        self.net = self.net.to(device = self.device)\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = 0.99999975\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e5 # no. of experiences between saving Mario Net\n",
    "\n",
    "        self.memory = TensorDictReplayBuffer(storage = LazyMemmapStorage(100000, device = torch.device(\"cpu\")))\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.gamma = 0.9 # discount rate\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "\n",
    "        self.burnin = 1e4 # min. experiences before training\n",
    "        self.learn_every = 3 # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 1e4 # no. of experiences between Q_target & Q_online sync\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        Given a state, choose an epsilon-greedy action and update value of step.\n",
    "        \n",
    "        Inputs:\n",
    "            state(``LazyFrame``): A single observation of the current state, dimension is (state_dim)\n",
    "        Outputs:\n",
    "            ``action_idx`` (``int``): An integer representing which action Mario will perform\n",
    "        \"\"\"\n",
    "        # Explore\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "        # Exploit\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state  = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # decrease exploration_rate\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        #increment step\n",
    "        self.curr_step += 1\n",
    "        return action_idx\n",
    "    \n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Add the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (``LazyFrame``): A single observation of the current state, dimension is (state_dim)\n",
    "        next_state (``LazyFrame``): A single observation of the next state, dimension is (state_dim)\n",
    "        action (``int``): An integer representing which action Mario will perform\n",
    "        reward (``float``): A float representing the reward Mario recieved for performing an action\n",
    "        done (``bool``): A boolean stating whether the episode is complete\n",
    "        \"\"\"\n",
    "\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        # self.memory.append((state, next_state, action, reward, done))\n",
    "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Sample experiences from memory\n",
    "        \"\"\"\n",
    "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
    "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()\n",
    "\n",
    "    ## td estimate and td target\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[np.arange(0, self.batch_size), action] # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[np.arange(0, self.batch_size), best_action]\n",
    "        return (reward  + (1 - done.float()) * self.gamma * next_Q).float()\n",
    "\n",
    "    ## updating model\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())\n",
    "    \n",
    "    ## save checkpoint\n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "        \n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "        \n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "        \n",
    "        # sample from memory\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # get td estimate\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # get td target\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 - Step 40 - Epsilon 0.9999900000487484 - Mean Reward 231.0 - Mean Length 40.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 0.416 - Time 2023-11-28T14:26:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20 - Step 2500 - Epsilon 0.9993751951936526 - Mean Reward 500.762 - Mean Length 119.048 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 27.964 - Time 2023-11-28T14:26:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 40 - Step 7391 - Epsilon 0.9981539558082899 - Mean Reward 577.293 - Mean Length 180.268 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 48.522 - Time 2023-11-28T14:27:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 60 - Step 10325 - Epsilon 0.9974220782390283 - Mean Reward 578.328 - Mean Length 169.262 - Mean Loss 0.19 - Mean Q Value 0.215 - Time Delta 31.744 - Time 2023-11-28T14:27:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 80 - Step 15011 - Epsilon 0.9962542822982645 - Mean Reward 601.691 - Mean Length 185.321 - Mean Loss 0.39 - Mean Q Value 0.99 - Time Delta 80.417 - Time 2023-11-28T14:29:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 - Step 19452 - Epsilon 0.9951488046348471 - Mean Reward 638.03 - Mean Length 194.12 - Mean Loss 0.413 - Mean Q Value 1.464 - Time Delta 77.27 - Time 2023-11-28T14:30:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 120 - Step 24064 - Epsilon 0.9940020591454143 - Mean Reward 658.99 - Mean Length 215.64 - Mean Loss 0.515 - Mean Q Value 2.656 - Time Delta 84.804 - Time 2023-11-28T14:32:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 140 - Step 27769 - Epsilon 0.9930817908880006 - Mean Reward 637.65 - Mean Length 203.78 - Mean Loss 0.616 - Mean Q Value 3.888 - Time Delta 72.279 - Time 2023-11-28T14:33:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 160 - Step 31419 - Epsilon 0.9921760169626717 - Mean Reward 656.91 - Mean Length 210.94 - Mean Loss 0.608 - Mean Q Value 5.197 - Time Delta 81.615 - Time 2023-11-28T14:34:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 180 - Step 35135 - Epsilon 0.9912547133394128 - Mean Reward 649.17 - Mean Length 201.24 - Mean Loss 0.524 - Mean Q Value 6.375 - Time Delta 90.544 - Time 2023-11-28T14:36:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200 - Step 37805 - Epsilon 0.9905932715162489 - Mean Reward 595.34 - Mean Length 183.53 - Mean Loss 0.536 - Mean Q Value 7.583 - Time Delta 69.758 - Time 2023-11-28T14:37:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 220 - Step 43566 - Epsilon 0.9891675962893499 - Mean Reward 608.41 - Mean Length 195.02 - Mean Loss 0.55 - Mean Q Value 8.451 - Time Delta 153.465 - Time 2023-11-28T14:39:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 240 - Step 47120 - Epsilon 0.9882891110949547 - Mean Reward 625.42 - Mean Length 193.51 - Mean Loss 0.56 - Mean Q Value 9.482 - Time Delta 97.981 - Time 2023-11-28T14:41:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 260 - Step 50738 - Epsilon 0.987395607630017 - Mean Reward 600.75 - Mean Length 193.19 - Mean Loss 0.575 - Mean Q Value 10.357 - Time Delta 104.454 - Time 2023-11-28T14:43:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 280 - Step 55203 - Epsilon 0.9862940420708072 - Mean Reward 608.93 - Mean Length 200.68 - Mean Loss 0.595 - Mean Q Value 11.164 - Time Delta 138.864 - Time 2023-11-28T14:45:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300 - Step 59767 - Epsilon 0.985169322202762 - Mean Reward 637.94 - Mean Length 219.62 - Mean Loss 0.62 - Mean Q Value 11.929 - Time Delta 143.271 - Time 2023-11-28T14:47:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 320 - Step 64589 - Epsilon 0.983982415987779 - Mean Reward 644.72 - Mean Length 210.23 - Mean Loss 0.65 - Mean Q Value 12.887 - Time Delta 153.359 - Time 2023-11-28T14:50:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 340 - Step 67285 - Epsilon 0.9833194352060596 - Mean Reward 626.31 - Mean Length 201.65 - Mean Loss 0.677 - Mean Q Value 13.661 - Time Delta 89.847 - Time 2023-11-28T14:51:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 360 - Step 71266 - Epsilon 0.982341273254346 - Mean Reward 633.76 - Mean Length 205.28 - Mean Loss 0.705 - Mean Q Value 14.563 - Time Delta 133.212 - Time 2023-11-28T14:54:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 380 - Step 74739 - Epsilon 0.9814887255030089 - Mean Reward 619.92 - Mean Length 195.36 - Mean Loss 0.722 - Mean Q Value 15.291 - Time Delta 115.115 - Time 2023-11-28T14:56:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzytitan/miniconda3/envs/rl/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "frames = []\n",
    "\n",
    "episodes = 400\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "        # Run agent on the state\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        # Remember\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "        frames.append(state[0])\n",
    "\n",
    "        # Check if end of game\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x7f723ac16a40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the animation\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "\n",
    "    writer = animation.FFMpegWriter(\n",
    "        fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "    anim.save(\"super_mario_training_autoencoder.mp4\", writer=writer)\n",
    "    plt.close()\n",
    "    return anim\n",
    "plot_animation(frames[-5000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
